"""
å·¥å…·æ¥å£æµ‹è¯•æ–‡ä»¶ - æ‰©å±•ç‰ˆ
"""

import json
import sys
import os
import re
import hashlib
from datetime import datetime
from typing import List, Dict, Any, Optional

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å‡è®¾å¯¼å…¥çš„æ¨¡å—åŠå‡½æ•°å­˜åœ¨
from logs.hot_topic_tool import process_hot_topic, process_hot_topics_batch, get_tool_info
from main.scraper.utils import (
    clean_text, extract_tags, generate_hash, categorize_topic,
    calculate_similarity, is_duplicate_topic, validate_platform,
    validate_rank, validate_heat_value, format_datetime, safe_json_loads,
    get_platform_icon, get_platform_name, safe_parse_datetime, process_tags
)

def test_text_processing_utils():
    """æµ‹è¯•æ–‡æœ¬å¤„ç†ç›¸å…³å·¥å…·å‡½æ•°"""
    print("=" * 50)
    print("æµ‹è¯•æ–‡æœ¬å¤„ç†å·¥å…·å‡½æ•°")
    print("=" * 50)
    
    # æµ‹è¯•clean_textå‡½æ•°
    test_texts = [
        "  è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬  \n\n  åŒ…å«å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œ  ",
        None,
        12345,
        "è¿™æ˜¯ä¸€ä¸ªè¶…é•¿æ–‡æœ¬ï¼Œ" * 20,  # æµ‹è¯•é•¿åº¦é™åˆ¶
        "æ–‡æœ¬ä¸­åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼š!@#$%^&*()_+{}[]|\\:;\"'<>,.?/"
    ]
    for idx, text in enumerate(test_texts):
        cleaned = clean_text(text)
        print(f"clean_textæµ‹è¯• {idx+1}: '{text}' -> '{cleaned}' (é•¿åº¦: {len(cleaned)})")
    
    # æµ‹è¯•calculate_similarityå‡½æ•°
    text_pairs = [
        ("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬", "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"),
        ("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬", "è¿™æ˜¯å¦ä¸€ä¸ªä¸åŒçš„æ–‡æœ¬"),
        ("å¾®åšçƒ­æœ", "å¾®åšçƒ­æœæ¦œ"),
        ("", "æµ‹è¯•æ–‡æœ¬")
    ]
    for idx, (text1, text2) in enumerate(text_pairs):
        similarity = calculate_similarity(text1, text2)
        print(f"æ–‡æœ¬ç›¸ä¼¼åº¦æµ‹è¯• {idx+1}: '{text1}' ä¸ '{text2}' -> {similarity:.2f}")
    
    print("æ–‡æœ¬å¤„ç†å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ\n")

def test_tag_and_category_utils():
    """æµ‹è¯•æ ‡ç­¾å’Œåˆ†ç±»ç›¸å…³å·¥å…·å‡½æ•°"""
    print("=" * 50)
    print("æµ‹è¯•æ ‡ç­¾å’Œåˆ†ç±»å·¥å…·å‡½æ•°")
    print("=" * 50)
    
    # æµ‹è¯•extract_tagså‡½æ•°
    test_titles = [
        "è¿™æ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜ğŸ”¥ æ–°æ¶ˆæ¯",
        "ç§‘æŠ€æ–°é—»ï¼šAIæŠ€æœ¯å–å¾—é‡å¤§çªç ´",
        "ä½“è‚²èµ›äº‹ï¼šè¶³çƒæ¯”èµ›ç»“æœå…¬å¸ƒ",
        "å¨±ä¹å…«å¦ï¼šæ˜æ˜Ÿç»“å©šå–œè®¯"
    ]
    for idx, title in enumerate(test_titles):
        tags = extract_tags(title)
        print(f"æ ‡ç­¾æå–æµ‹è¯• {idx+1}: '{title}' -> {tags}")
    
    # æµ‹è¯•process_tagså‡½æ•°
    test_tag_lists = [
        ["è¶…é•¿æ ‡ç­¾" * 20, "æ­£å¸¸æ ‡ç­¾", ""],  # åŒ…å«è¶…é•¿æ ‡ç­¾å’Œç©ºæ ‡ç­¾
        "å•ä¸ªæ ‡ç­¾å­—ç¬¦ä¸²",  # éåˆ—è¡¨è¾“å…¥
        None,  # ç©ºå€¼
        ["æ ‡ç­¾1", "æ ‡ç­¾2", "æ ‡ç­¾3", "æ ‡ç­¾4", "æ ‡ç­¾5", "æ ‡ç­¾6"]  # æµ‹è¯•æ•°é‡é™åˆ¶
    ]
    for idx, tags in enumerate(test_tag_lists):
        processed = process_tags(tags, max_length=10)
        print(f"æ ‡ç­¾å¤„ç†æµ‹è¯• {idx+1}: {tags} -> {processed}")
    
    # æµ‹è¯•categorize_topicå‡½æ•°
    test_titles = [
        "æ˜æ˜Ÿæ¼”å”±ä¼šé—¨ç¥¨å”®ç½„",
        "AIæŠ€æœ¯æœ€æ–°çªç ´",
        "è‚¡å¸‚å¤§æ¶¨",
        "è¶³çƒæ¯”èµ›ç»“æœ",
        "æœªçŸ¥åˆ†ç±»æµ‹è¯•"
    ]
    for idx, title in enumerate(test_titles):
        category = categorize_topic(title)
        print(f"è¯é¢˜åˆ†ç±»æµ‹è¯• {idx+1}: '{title}' -> {category}")
    
    print("æ ‡ç­¾å’Œåˆ†ç±»å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ\n")

def test_validation_utils():
    """æµ‹è¯•æ•°æ®éªŒè¯ç›¸å…³å·¥å…·å‡½æ•°"""
    print("=" * 50)
    print("æµ‹è¯•æ•°æ®éªŒè¯å·¥å…·å‡½æ•°")
    print("=" * 50)
    
    # æµ‹è¯•validate_platformå‡½æ•°
    test_platforms = ['weibo', 'zhihu', 'douyin', 'invalid_platform', '']
    for idx, platform in enumerate(test_platforms):
        is_valid = validate_platform(platform)
        print(f"å¹³å°éªŒè¯æµ‹è¯• {idx+1}: '{platform}' -> {is_valid}")
    
    # æµ‹è¯•validate_rankå‡½æ•°
    test_ranks = [1, 50, 1000, 0, 1001, "10", None]
    for idx, rank in enumerate(test_ranks):
        is_valid = validate_rank(rank)
        print(f"æ’åéªŒè¯æµ‹è¯• {idx+1}: {rank} -> {is_valid}")
    
    # æµ‹è¯•validate_heat_valueå‡½æ•°
    test_heat_values = [1000, 0, None, -100, "1000", 123.45]
    for idx, heat in enumerate(test_heat_values):
        is_valid = validate_heat_value(heat)
        print(f"çƒ­åº¦å€¼éªŒè¯æµ‹è¯• {idx+1}: {heat} -> {is_valid}")
    
    print("æ•°æ®éªŒè¯å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ\n")

def test_datetime_utils():
    """æµ‹è¯•æ—¥æœŸæ—¶é—´ç›¸å…³å·¥å…·å‡½æ•°"""
    print("=" * 50)
    print("æµ‹è¯•æ—¥æœŸæ—¶é—´å·¥å…·å‡½æ•°")
    print("=" * 50)
    
    # æµ‹è¯•format_datetimeå‡½æ•°
    test_dates = [
        datetime(2023, 1, 1, 12, 0, 0),
        datetime(2023, 12, 31, 23, 59, 59)
    ]
    for idx, dt in enumerate(test_dates):
        formatted = format_datetime(dt)
        print(f"æ—¥æœŸæ ¼å¼åŒ–æµ‹è¯• {idx+1}: {dt} -> {formatted}")
    
    # æµ‹è¯•safe_parse_datetimeå‡½æ•°
    test_date_strings = [
        "2023-01-01T12:00:00",
        "2023-01-01 12:00:00",
        "2023-01-01",
        "invalid_date",
        datetime(2023, 1, 1),  # å·²ä¸ºdatetimeå¯¹è±¡
        123456789,  # æ— æ•ˆç±»å‹
        None
    ]
    for idx, date_val in enumerate(test_date_strings):
        parsed = safe_parse_datetime(date_val)
        print(f"æ—¥æœŸè§£ææµ‹è¯• {idx+1}: {date_val} -> {parsed} (ç±»å‹: {type(parsed)})")
    
    print("æ—¥æœŸæ—¶é—´å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ\n")

def test_other_utils():
    """æµ‹è¯•å…¶ä»–å·¥å…·å‡½æ•°"""
    print("=" * 50)
    print("æµ‹è¯•å…¶ä»–å·¥å…·å‡½æ•°")
    print("=" * 50)
    
    # æµ‹è¯•generate_hashå‡½æ•°
    test_contents = [
        "æµ‹è¯•å“ˆå¸Œç”Ÿæˆ",
        "æµ‹è¯•å“ˆå¸Œç”Ÿæˆ",  # ç›¸åŒå†…å®¹
        "ä¸åŒçš„æµ‹è¯•å†…å®¹"
    ]
    for idx, content in enumerate(test_contents):
        hash_val = generate_hash(content)
        print(f"å“ˆå¸Œç”Ÿæˆæµ‹è¯• {idx+1}: '{content}' -> {hash_val}")
    
    # æµ‹è¯•safe_json_loadså‡½æ•°
    test_json_strings = [
        '{"name": "æµ‹è¯•", "value": 123}',
        'invalid_json',
        None,
        12345
    ]
    for idx, json_str in enumerate(test_json_strings):
        result = safe_json_loads(json_str, default={})
        print(f"JSONè§£ææµ‹è¯• {idx+1}: {json_str} -> {result} (ç±»å‹: {type(result)})")
    
    # æµ‹è¯•get_platform_iconå’Œget_platform_nameå‡½æ•°
    test_platforms = ['weibo', 'zhihu', 'invalid_platform']
    for idx, platform in enumerate(test_platforms):
        icon = get_platform_icon(platform)
        name = get_platform_name(platform)
        print(f"å¹³å°ä¿¡æ¯æµ‹è¯• {idx+1}: '{platform}' -> åç§°: {name}, å›¾æ ‡: {icon}")
    
    # æµ‹è¯•is_duplicate_topicå‡½æ•°
    test_topic_pairs = [
        (
            {'title': 'è¿™æ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜'},
            {'title': 'è¿™æ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜'}
        ),
        (
            {'title': 'è¿™æ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜'},
            {'title': 'è¿™æ˜¯å¦ä¸€ä¸ªè¯é¢˜'}
        ),
        (
            {'title': 'AIæŠ€æœ¯çªç ´'},
            {'title': 'AIæŠ€æœ¯æœ€æ–°çªç ´'}
        )
    ]
    for idx, (topic1, topic2) in enumerate(test_topic_pairs):
        is_duplicate = is_duplicate_topic(topic1, topic2)
        print(f"è¯é¢˜é‡å¤æ£€æµ‹æµ‹è¯• {idx+1}: '{topic1['title']}' ä¸ '{topic2['title']}' -> {is_duplicate}")
    
    print("å…¶ä»–å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ\n")

def test_single_topic():
    """æµ‹è¯•å•ä¸ªè¯é¢˜å¤„ç†"""
    print("=" * 50)
    print("æµ‹è¯•å•ä¸ªè¯é¢˜å¤„ç†")
    print("=" * 50)
    
    # æµ‹è¯•æ•°æ®
    test_data = {
        'platform': 'weibo',
        'title': 'è¿™æ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜ğŸ”¥ æ–°æ¶ˆæ¯',
        'rank': 1,
        'heat_value': 10000,
        'url': 'https://example.com'
    }
    
    # æ‰§è¡Œå•ä¸ªè¯é¢˜å¤„ç†å‡½æ•°
    result = process_hot_topic(test_data)
    if result:
        print("âœ… å•ä¸ªè¯é¢˜å¤„ç†æˆåŠŸ:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print("âŒ å•ä¸ªè¯é¢˜å¤„ç†å¤±è´¥")
    
    print("å•ä¸ªè¯é¢˜å¤„ç†æµ‹è¯•å®Œæˆ\n")

def test_batch_topics():
    """æµ‹è¯•æ‰¹é‡è¯é¢˜å¤„ç†"""
    print("=" * 50)
    print("æµ‹è¯•æ‰¹é‡è¯é¢˜å¤„ç†")
    print("=" * 50)
    
    # æµ‹è¯•æ•°æ®
    test_data_list = [
        {
            'platform': 'weibo',
            'title': 'è¿™æ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜ğŸ”¥ æ–°æ¶ˆæ¯',
            'rank': 1,
            'heat_value': 10000,
            'url': 'https://example.com'
        },
        {
            'platform': 'zhihu',
            'title': 'AIæŠ€æœ¯æœ€æ–°çªç ´',
            'rank': 2,
            'heat_value': 8000
        },
        {
            'platform': 'toutiao',
            'title': 'è‚¡å¸‚å¤§æ¶¨ï¼ŒæŠ•èµ„è€…ä¿¡å¿ƒå¢å¼º',
            'rank': 3,
            'heat_value': 6000
        },
        {
            'platform': 'weibo',
            'title': 'è¿™æ˜¯ä¸€ä¸ªçƒ­é—¨è¯é¢˜ğŸ”¥ æ–°æ¶ˆæ¯',  # é‡å¤æ•°æ®
            'rank': 4,
            'heat_value': 5000
        },
        {
            'platform': 'invalid_platform',  # æ— æ•ˆå¹³å°
            'title': 'æ— æ•ˆå¹³å°æµ‹è¯•',
            'rank': 5
        }
    ]
    
    # æ‰§è¡Œæ‰¹é‡è¯é¢˜å¤„ç†å‡½æ•°
    result = process_hot_topics_batch(test_data_list)
    print("âœ… æ‰¹é‡è¯é¢˜å¤„ç†ç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    print("æ‰¹é‡è¯é¢˜å¤„ç†æµ‹è¯•å®Œæˆ\n")

def test_tool_info():
    """æµ‹è¯•å·¥å…·ä¿¡æ¯è·å–"""
    print("=" * 50)
    print("æµ‹è¯•å·¥å…·ä¿¡æ¯è·å–")
    print("=" * 50)
    
    # æ‰§è¡Œå·¥å…·ä¿¡æ¯è·å–å‡½æ•°
    info = get_tool_info()
    print("âœ… å·¥å…·ä¿¡æ¯:")
    print(json.dumps(info, ensure_ascii=False, indent=2))
    
    print("å·¥å…·ä¿¡æ¯æµ‹è¯•å®Œæˆ\n")

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("=" * 50)
    print("æµ‹è¯•é”™è¯¯å¤„ç†")
    print("=" * 50)
    
    # æµ‹è¯•ç¼ºå°‘å¿…éœ€å­—æ®µ
    invalid_data = {
        'platform': 'weibo',
        'title': '',  # ç©ºæ ‡é¢˜
        'rank': 1
    }
    
    # æ‰§è¡Œå•ä¸ªè¯é¢˜å¤„ç†å‡½æ•°ï¼ˆç©ºæ ‡é¢˜æµ‹è¯•ï¼‰
    result = process_hot_topic(invalid_data)
    print(f"ç©ºæ ‡é¢˜æµ‹è¯•: {result is None}")
    
    # æµ‹è¯•æ— æ•ˆæ’å
    invalid_rank_data = {
        'platform': 'weibo',
        'title': 'æµ‹è¯•æ ‡é¢˜',
        'rank': 0  # æ— æ•ˆæ’å
    }
    
    # æ‰§è¡Œå•ä¸ªè¯é¢˜å¤„ç†å‡½æ•°ï¼ˆæ— æ•ˆæ’åæµ‹è¯•ï¼‰
    result = process_hot_topic(invalid_rank_data)
    print(f"æ— æ•ˆæ’åæµ‹è¯•: {result is None}")
    
    # æµ‹è¯•æ— æ•ˆçƒ­åº¦å€¼
    invalid_heat_data = {
        'platform': 'weibo',
        'title': 'æµ‹è¯•æ ‡é¢˜',
        'rank': 1,
        'heat_value': -100  # è´Ÿæ•°çƒ­åº¦å€¼
    }
    
    # æ‰§è¡Œå•ä¸ªè¯é¢˜å¤„ç†å‡½æ•°ï¼ˆæ— æ•ˆçƒ­åº¦å€¼æµ‹è¯•ï¼‰
    result = process_hot_topic(invalid_heat_data)
    print(f"æ— æ•ˆçƒ­åº¦å€¼æµ‹è¯•: {result is None}")
    
    print("é”™è¯¯å¤„ç†æµ‹è¯•å®Œæˆ\n")

def main():
    """ä¸»æµ‹è¯•å‡½æ•° - æ‰§è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("çƒ­æœè¯é¢˜å¤„ç†å·¥å…· - å…¨é¢æµ‹è¯•")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    test_text_processing_utils()      # æµ‹è¯•æ–‡æœ¬å¤„ç†ç›¸å…³å‡½æ•°
    test_tag_and_category_utils()     # æµ‹è¯•æ ‡ç­¾å’Œåˆ†ç±»ç›¸å…³å‡½æ•°
    test_validation_utils()           # æµ‹è¯•æ•°æ®éªŒè¯ç›¸å…³å‡½æ•°
    test_datetime_utils()             # æµ‹è¯•æ—¥æœŸæ—¶é—´ç›¸å…³å‡½æ•°
    test_other_utils()                # æµ‹è¯•å…¶ä»–å·¥å…·å‡½æ•°
    test_single_topic()               # æµ‹è¯•å•ä¸ªè¯é¢˜å¤„ç†
    test_batch_topics()               # æµ‹è¯•æ‰¹é‡è¯é¢˜å¤„ç†
    test_tool_info()                  # æµ‹è¯•å·¥å…·ä¿¡æ¯è·å–
    test_error_handling()             # æµ‹è¯•é”™è¯¯å¤„ç†
    
    print("=" * 50)
    print("æ‰€æœ‰æµ‹è¯•å®Œæˆ")
    print("=" * 50)

if __name__ == "__main__":
    main()